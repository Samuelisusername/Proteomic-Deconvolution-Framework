Assuming unrestricted shared filesystem usage.
None
host: student-net-rz-1815.intern.ethz.ch
Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job stats:
job                  count
-----------------  -------
visualize_results        1
total                    1

Select jobs to execute...
Execute 1 jobs...
[Tue May  6 16:49:02 2025]
localrule visualize_results:
    input: real_fracs.tsv, real_coarse_fracs.tsv, RANDOM_GUESSING-Results.txt
    output: RANDOM_GUESSING_errors.png, RANDOM_GUESSING_fractions_compare.png
    jobid: 0
    reason: Missing output files: RANDOM_GUESSING_errors.png
    wildcards: method=RANDOM_GUESSING
    resources: tmpdir=/var/folders/zq/9vmc9tbn5pv_0b8_c7ffd6nh0000gn/T

Waiting at most 5 seconds for missing files:
RANDOM_GUESSING_errors.png (missing locally)
RANDOM_GUESSING_fractions_compare.png (missing locally)
MissingOutputException in rule visualize_results in file "/Users/samuelgair/Desktop/BA_code/snakemake_fun/workflow/Snakefile", line 51:
Job 0 completed successfully, but some output files are missing. Missing files after 5 seconds. This might be due to filesystem latency. If that is the case, consider to increase the wait time with --latency-wait:
RANDOM_GUESSING_errors.png (missing locally, parent dir not present)
RANDOM_GUESSING_fractions_compare.png (missing locally, parent dir not present)
Shutting down, this might take some time.
Exiting because a job execution failed. Look below for error messages
[Tue May  6 16:49:09 2025]
Error in rule visualize_results:
    message: None
    jobid: 0
    input: real_fracs.tsv, real_coarse_fracs.tsv, RANDOM_GUESSING-Results.txt
    output: RANDOM_GUESSING_errors.png, RANDOM_GUESSING_fractions_compare.png
    shell:
        python3 visualizing_results.py RANDOM_GUESSING-Results.txt
        (command exited with non-zero exit code)
Complete log(s): /Users/samuelgair/Desktop/BA_code/snakemake_fun/.snakemake/log/2025-05-06T164902.013808.snakemake.log
WorkflowError:
At least one job did not complete successfully.
